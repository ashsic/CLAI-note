# CLAI-note
A CLI program written in Python that creates and exports LLM-enhanced notes.

The program will be written in Python, mainly using functionality
provided by Typer, as well as Fire, PyTorch, and other dependencies (TBD).

The main goal of the project is to create something useful for at least one
person - me. It will face trial by fire in my third semester.

## Core Functionality - Main command and its options

The core functionality is to allow users to create a note via a CLI command,
with options specifying the following:
  - Formatting for the note (will have a default markdown style)
  - Where and how to export the note (Anki, Obsidian, etc.)
  - Tags to be associated with the note - sort by tag functionality?
  - Whether or not to enhance the note with an LLM, with its own options:
    - Which LLM to use, including local LLMs and API endpoints
    - What prompt to use, either custom or selected from pre existing options
    - Where to draw RAG resources from (ie. use all notes of a given tag as context)
    - Whether to display the output in the CLI or not
    - How to enhance the note, (ie. rewrite for clarity, provide code sample, 
      translate, fill in gaps - part of prompt?)

## Secondary Functionality - Config and more

The program should come with a set of core programs/formats that it can
export to natively, like markdown, Anki (.apkg), maybe Notion (HTML?).
Users should also have a way to configure custom output formats as well.

The program should stand on its own two legs - It should be entirely usable
within the terminal, without an LLM or an Internet connection. Notes will need
to be navigable in some way - does it need its own Obsidian style "vault"?
Or will it exist within the default filesystem?

There should be a way to create "rough drafts" of notes, or notes that do not
get exported upon creation, but may be edited and exported at will anytime after.

## Future Possibilities

The program could progress to a prototype personal assistant. If there is a way
to consistently query the LLM with the relevant context from the user's notes,
it would become much more useful. RAG techniques, prompt engineering, and trial
and error could possibly produce a useful result here.

Other coding functionality could be added, like getting the LLM to explain a code
snippet, generating/fixing my code in real time, etc.

Could the LLM generate and execute commands in my shell in real time? Could one 
describe a desired filesystem tree and have it generated by the LLM?
